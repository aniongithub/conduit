#!/usr/local/bin/python3.11

import argparse
import os
from conduit.pipeline import Pipeline
from pathlib import Path
from conduit.common import logger, set_log_level

# Adapted from: https://stackoverflow.com/a/68829190/802203
class kwargs_append_action(argparse.Action):
    def __call__(self, parser, args, values, option_string=None):
        try:
            if len(values[0]) > 1:
                d = dict(map(lambda x: x.split('='),values[0].split(' ')))
            else:
                d = {}
        except ValueError as ex:
            raise argparse.ArgumentError(self, f"Could not parse argument \"{values}\" as k1=v1 k2=v2 ... format")
        setattr(args, self.dest, d)

def configure_logger(args):
    """Configure logger based on CLI arguments"""
    from conduit.common import logger
    
    log_config = {
        'level': args.log_level,
        'format_type': getattr(args, 'log_format', 'color'),
        'output': getattr(args, 'log_output', 'console'),
        'use_colors': None if not getattr(args, 'log_no_colors', False) else False,
        'use_indentation': not getattr(args, 'log_no_indentation', False),
        'reset': True  # Always reset when configuring from CLI
    }
    
    # Add filename if file output is requested
    if hasattr(args, 'log_file') and args.log_file:
        log_config['filename'] = args.log_file
    elif log_config['output'] in ('file', 'both'):
        log_config['filename'] = 'conduit.log'  # Default filename
    
    # Configure the logger
    logger(**log_config)

def cmd_run(args):
    """Run a pipeline configuration"""
    from conduit.pipeline import Pipeline
    from conduit.common import logger
    
    # Set our arguments in the environment for expansion
    for arg, value in args.args.items():
        os.environ[arg] = value

    pipeline_path = Path(args.pipeline).absolute()
    os.chdir(args.working_directory)
    
    try:
        output = Pipeline.from_config(pipeline_path, expand_env=True, stop_on_error=args.stop_on_error)
        result = output.run(None)
        
        # Check element metrics to determine exit code
        if hasattr(output, 'stats') and output.stats and hasattr(output.stats, 'element_metrics'):
            failed_elements = [m for m in output.stats.element_metrics if m.status == "failed"]
            if failed_elements:
                logger().error(f"Pipeline completed with {len(failed_elements)} failed element(s)")
                return 1  # Error exit code
        
        logger().info("Pipeline completed successfully")
        return 0  # Success exit code
        
    except Exception as e:
        logger().error(f"Pipeline execution failed: {str(e)}")
        return 1  # Error exit code

def cmd_visualize(args):
    """Visualize a pipeline structure without running it"""
    from conduit.pipeline import Pipeline
    from conduit.common import logger
    
    # Set our arguments in the environment for expansion
    for arg, value in args.args.items():
        os.environ[arg] = value

    try:
        pipeline_path = Path(args.pipeline).absolute()
        os.chdir(args.working_directory)
        output = Pipeline.from_config(pipeline_path, expand_env=True, stop_on_error=args.stop_on_error)

        print("Pipeline structure:")
        graph = output.to_graph()

        try:
            from asciinet import graph_to_ascii
            logger().info("Using asciinet for pipeline visualization")
            use_dagviz = False
        except ImportError:
            logger().warning("asciinet cannot be imported, using py-dagviz for visualization instead. Try installing Java in your environment if you want to use asciinet.")
            use_dagviz = True
            from dagviz import visualize_dag

        if use_dagviz:
            print(visualize_dag(graph, round_angle=True))
        else:
            print(graph_to_ascii(graph))
        
        return 0  # Success exit code
        
    except Exception as e:
        logger().error(f"Pipeline visualization failed: {str(e)}")
        return 1  # Error exit code

def cmd_serve(args):
    """Start the Conduit server"""
    from conduit.common import logger
    
    try:
        from conduit.server import start_server
        start_server(host=args.host, port=args.port, working_directory=args.working_directory)
    except ImportError:
        logger().error("FastAPI and uvicorn are required for server mode. Install with: pip install fastapi uvicorn")
        return 1

def cmd_generate_schema(args):
    """Generate the JSON schema for pipeline configurations"""
    from conduit.common import logger
    
    if hasattr(args, 'help_env') and args.help_env:
        print("Environment Variables for Schema Generation:")
        print("  CONDUIT_SEARCH_PATHS - Comma-separated list of additional search paths for pipeline elements")
        print("  CONDUIT_SCHEMA_PATH  - Full path for output schema file (overrides default location)")
        print()
        print("Example usage:")
        print("  export CONDUIT_SEARCH_PATHS=/path/to/custom/elements,/another/path")
        print("  export CONDUIT_SCHEMA_PATH=/custom/output/schema.json")
        print("  ./conduit-cli generate-schema")
        return 0
    
    try:
        from conduit.schema_generator import main as generate_schema
        logger().info("Generating Conduit pipeline schema...")
        generate_schema()
        logger().info("Schema generation completed successfully")
        return 0
    except Exception as e:
        logger().error(f"Schema generation failed: {str(e)}")
        return 1

def main():
    parser = argparse.ArgumentParser(description="Conduit - Streaming, declarative pipelined data processing library for Python")
    
    # Logging configuration options
    parser.add_argument("--log-level", choices=["DEBUG", "INFO", "WARNING", "ERROR"], default="INFO", 
        help="Set the logging level (default: INFO)")
    parser.add_argument("--log-format", choices=["color", "simple", "structured"], default="color",
        help="Set the log format type (default: color)")
    parser.add_argument("--log-output", choices=["console", "file", "both"], default="console",
        help="Set the log output destination (default: console)")
    parser.add_argument("--log-file", type=str, default=None,
        help="Log file path (required when log-output includes 'file')")
    parser.add_argument("--log-no-colors", action="store_true", default=False,
        help="Disable colored output (auto-detected by default)")
    parser.add_argument("--log-no-indentation", action="store_true", default=False,
        help="Disable log indentation for nested operations")
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # Run command
    run_parser = subparsers.add_parser('run', help='Run a pipeline configuration')
    run_parser.add_argument("pipeline", help="Path to the pipeline configuration to run")
    run_parser.add_argument("-w", "--working-directory", help="Set the working directory for this pipeline", default=os.getcwd())
    run_parser.add_argument("-a", "--args", dest="args", nargs="*", required=False, default={},
        action=kwargs_append_action, metavar="KEY=VALUE", help="Define arguments that will be substituted in the pipeline file")
    run_parser.add_argument("--continue-on-error", action="store_false", help="Continue pipeline execution even if an element fails", default=True, dest="stop_on_error")
    
    # Visualize command
    vis_parser = subparsers.add_parser('visualize', help='Visualize pipeline structure without running')
    vis_parser.add_argument("pipeline", help="Path to the pipeline configuration to visualize")
    vis_parser.add_argument("-w", "--working-directory", help="Set the working directory for this pipeline", default=os.getcwd())
    vis_parser.add_argument("-a", "--args", dest="args", nargs="*", required=False, default={},
        action=kwargs_append_action, metavar="KEY=VALUE", help="Define arguments that will be substituted in the pipeline file")
    vis_parser.add_argument("--continue-on-error", action="store_false", help="Continue pipeline execution even if an element fails", default=True, dest="stop_on_error")
    
    # Serve command
    serve_parser = subparsers.add_parser('serve', help='Start the Conduit server')
    serve_parser.add_argument("--host", default="127.0.0.1", help="Host to bind the server to (default: 127.0.0.1)")
    serve_parser.add_argument("--port", type=int, default=8000, help="Port to bind the server to (default: 8000)")
    serve_parser.add_argument("-w", "--working-directory", help="Set the working directory for pipeline execution", default=os.getcwd())
    
    # Generate schema command
    schema_parser = subparsers.add_parser('generate-schema', help='Generate JSON schema for pipeline configurations')
    schema_parser.add_argument("--help-env", action="store_true", help="Show environment variable configuration options")
    
    args = parser.parse_args()
    
    # Configure logger early based on CLI arguments
    configure_logger(args)
    
    if args.command is None:
        parser.print_help()
        return 1
    
    # Route to appropriate command
    if args.command == 'run':
        return cmd_run(args)
    elif args.command == 'visualize':
        return cmd_visualize(args)
    elif args.command == 'serve':
        return cmd_serve(args)
    elif args.command == 'generate-schema':
        return cmd_generate_schema(args)

if __name__ == "__main__":
    cwd = os.getcwd()
    try:
        exit_code = main()
        exit(exit_code if exit_code is not None else 0)
    finally:
        os.chdir(cwd)